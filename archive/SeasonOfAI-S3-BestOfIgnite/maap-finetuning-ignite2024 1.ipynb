{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning using MaaP (Model-as-a-Platform)\n",
    "\n",
    "This sample shows how use `chat-completion` components from Azure Machine Learning's `azureml` system registry to finetune a model. We then deploy the fine tuned model to an online endpoint for real time inference.\n",
    "\n",
    "### Model\n",
    "We will use the `Phi-3.5-mini-instruct` model to show how user can finetune a model for chat-completion task.\n",
    "\n",
    "### Outline\n",
    "* Setup pre-requisites such as compute.\n",
    "* Pick a model to fine tune.\n",
    "* Pick and explore training data.\n",
    "* Configure the fine tuning job.\n",
    "* Run the fine tuning job.\n",
    "* Review training and evaluation metrics. \n",
    "* Register the fine tuned model. \n",
    "* Deploy the fine tuned model for real time inference.\n",
    "* (Optional) Download the fine tuned model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup pre-requisites\n",
    "* Install dependencies\n",
    "* Connect to AzureML Workspace. Learn more at [set up SDK authentication](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-setup-authentication?tabs=sdk). Replace  `<WORKSPACE_NAME>`, `<RESOURCE_GROUP>` and `<SUBSCRIPTION_ID>` below.\n",
    "* Connect to `azureml` system registry\n",
    "* Set an optional experiment name\n",
    "* Check or create compute. A single GPU node can have multiple GPU cards. For example, in one node of `Standard_NC24rs_v3` there are 4 NVIDIA V100 GPUs while in `Standard_NC12s_v3`, there are 2 NVIDIA V100 GPUs. Refer to the [docs](https://learn.microsoft.com/en-us/azure/virtual-machines/sizes-gpu) for this information. The number of GPU cards per node is set in the param `gpus_per_node` below. Setting this value correctly will ensure utilization of all GPUs in the node. The recommended GPU compute SKUs can be found [here](https://learn.microsoft.com/en-us/azure/virtual-machines/ncv3-series) and [here](https://learn.microsoft.com/en-us/azure/virtual-machines/ndv2-series)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install dependencies by running below cell. This is not an optional step if running in a new environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure-ai-ml in /opt/anaconda3/lib/python3.12/site-packages (1.21.1)\n",
      "Requirement already satisfied: pyyaml>=5.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from azure-ai-ml) (6.0.1)\n",
      "Requirement already satisfied: msrest>=0.6.18 in /opt/anaconda3/lib/python3.12/site-packages (from azure-ai-ml) (0.7.1)\n",
      "Requirement already satisfied: azure-core>=1.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from azure-ai-ml) (1.31.0)\n",
      "Requirement already satisfied: azure-mgmt-core>=1.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from azure-ai-ml) (1.4.0)\n",
      "Requirement already satisfied: marshmallow>=3.5 in /opt/anaconda3/lib/python3.12/site-packages (from azure-ai-ml) (3.23.0)\n",
      "Requirement already satisfied: jsonschema>=4.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from azure-ai-ml) (4.19.2)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from azure-ai-ml) (4.66.4)\n",
      "Requirement already satisfied: strictyaml in /opt/anaconda3/lib/python3.12/site-packages (from azure-ai-ml) (1.7.3)\n",
      "Requirement already satisfied: colorama in /opt/anaconda3/lib/python3.12/site-packages (from azure-ai-ml) (0.4.6)\n",
      "Requirement already satisfied: pyjwt in /opt/anaconda3/lib/python3.12/site-packages (from azure-ai-ml) (2.8.0)\n",
      "Requirement already satisfied: azure-storage-blob>=12.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from azure-ai-ml) (12.19.0)\n",
      "Requirement already satisfied: azure-storage-file-share in /opt/anaconda3/lib/python3.12/site-packages (from azure-ai-ml) (12.19.0)\n",
      "Requirement already satisfied: azure-storage-file-datalake>=12.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from azure-ai-ml) (12.17.0)\n",
      "Requirement already satisfied: pydash>=6.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from azure-ai-ml) (8.0.3)\n",
      "Requirement already satisfied: isodate in /opt/anaconda3/lib/python3.12/site-packages (from azure-ai-ml) (0.7.2)\n",
      "Requirement already satisfied: azure-common>=1.1 in /opt/anaconda3/lib/python3.12/site-packages (from azure-ai-ml) (1.1.28)\n",
      "Requirement already satisfied: typing-extensions in /opt/anaconda3/lib/python3.12/site-packages (from azure-ai-ml) (4.11.0)\n",
      "Requirement already satisfied: opencensus-ext-azure in /opt/anaconda3/lib/python3.12/site-packages (from azure-ai-ml) (1.1.13)\n",
      "Requirement already satisfied: opencensus-ext-logging in /opt/anaconda3/lib/python3.12/site-packages (from azure-ai-ml) (0.1.1)\n",
      "Requirement already satisfied: requests>=2.21.0 in /opt/anaconda3/lib/python3.12/site-packages (from azure-core>=1.23.0->azure-ai-ml) (2.32.2)\n",
      "Requirement already satisfied: six>=1.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from azure-core>=1.23.0->azure-ai-ml) (1.16.0)\n",
      "Requirement already satisfied: cryptography>=2.1.4 in /opt/anaconda3/lib/python3.12/site-packages (from azure-storage-blob>=12.10.0->azure-ai-ml) (42.0.5)\n",
      "Collecting azure-storage-blob>=12.10.0 (from azure-ai-ml)\n",
      "  Using cached azure_storage_blob-12.23.1-py3-none-any.whl.metadata (26 kB)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jsonschema>=4.0.0->azure-ai-ml) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/anaconda3/lib/python3.12/site-packages (from jsonschema>=4.0.0->azure-ai-ml) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/anaconda3/lib/python3.12/site-packages (from jsonschema>=4.0.0->azure-ai-ml) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/anaconda3/lib/python3.12/site-packages (from jsonschema>=4.0.0->azure-ai-ml) (0.10.6)\n",
      "Requirement already satisfied: packaging>=17.0 in /opt/anaconda3/lib/python3.12/site-packages (from marshmallow>=3.5->azure-ai-ml) (23.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from msrest>=0.6.18->azure-ai-ml) (2024.6.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from msrest>=0.6.18->azure-ai-ml) (2.0.0)\n",
      "Requirement already satisfied: azure-identity<2.0.0,>=1.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from opencensus-ext-azure->azure-ai-ml) (1.19.0)\n",
      "Requirement already satisfied: opencensus<1.0.0,>=0.11.4 in /opt/anaconda3/lib/python3.12/site-packages (from opencensus-ext-azure->azure-ai-ml) (0.11.4)\n",
      "Requirement already satisfied: psutil>=5.6.3 in /opt/anaconda3/lib/python3.12/site-packages (from opencensus-ext-azure->azure-ai-ml) (5.9.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from strictyaml->azure-ai-ml) (2.9.0.post0)\n",
      "Requirement already satisfied: msal>=1.30.0 in /opt/anaconda3/lib/python3.12/site-packages (from azure-identity<2.0.0,>=1.5.0->opencensus-ext-azure->azure-ai-ml) (1.31.0)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from azure-identity<2.0.0,>=1.5.0->opencensus-ext-azure->azure-ai-ml) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/anaconda3/lib/python3.12/site-packages (from cryptography>=2.1.4->azure-storage-blob>=12.10.0->azure-ai-ml) (1.16.0)\n",
      "Requirement already satisfied: opencensus-context>=0.1.3 in /opt/anaconda3/lib/python3.12/site-packages (from opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml) (0.1.3)\n",
      "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml) (2.21.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.21.0->azure-core>=1.23.0->azure-ai-ml) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.21.0->azure-core>=1.23.0->azure-ai-ml) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.21.0->azure-core>=1.23.0->azure-ai-ml) (2.2.2)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.18->azure-ai-ml) (3.2.2)\n",
      "Requirement already satisfied: pycparser in /opt/anaconda3/lib/python3.12/site-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob>=12.10.0->azure-ai-ml) (2.21)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/anaconda3/lib/python3.12/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml) (1.65.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in /opt/anaconda3/lib/python3.12/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml) (3.20.3)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/anaconda3/lib/python3.12/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml) (1.24.0)\n",
      "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /opt/anaconda3/lib/python3.12/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml) (2.35.0)\n",
      "Requirement already satisfied: portalocker<3,>=1.4 in /opt/anaconda3/lib/python3.12/site-packages (from msal-extensions>=1.2.0->azure-identity<2.0.0,>=1.5.0->opencensus-ext-azure->azure-ai-ml) (2.10.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/anaconda3/lib/python3.12/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/anaconda3/lib/python3.12/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml) (4.9)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/anaconda3/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.4->opencensus-ext-azure->azure-ai-ml) (0.4.8)\n",
      "Using cached azure_storage_blob-12.23.1-py3-none-any.whl (405 kB)\n",
      "Installing collected packages: azure-storage-blob\n",
      "  Attempting uninstall: azure-storage-blob\n",
      "    Found existing installation: azure-storage-blob 12.19.0\n",
      "    Uninstalling azure-storage-blob-12.19.0:\n",
      "      Successfully uninstalled azure-storage-blob-12.19.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "azureml-mlflow 1.58.0 requires azure-storage-blob<=12.19.0,>=12.5.0, but you have azure-storage-blob 12.23.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed azure-storage-blob-12.23.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: azure-identity in /opt/anaconda3/lib/python3.12/site-packages (1.19.0)\n",
      "Requirement already satisfied: azure-core>=1.31.0 in /opt/anaconda3/lib/python3.12/site-packages (from azure-identity) (1.31.0)\n",
      "Requirement already satisfied: cryptography>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from azure-identity) (42.0.5)\n",
      "Requirement already satisfied: msal>=1.30.0 in /opt/anaconda3/lib/python3.12/site-packages (from azure-identity) (1.31.0)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from azure-identity) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from azure-identity) (4.11.0)\n",
      "Requirement already satisfied: requests>=2.21.0 in /opt/anaconda3/lib/python3.12/site-packages (from azure-core>=1.31.0->azure-identity) (2.32.2)\n",
      "Requirement already satisfied: six>=1.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from azure-core>=1.31.0->azure-identity) (1.16.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/anaconda3/lib/python3.12/site-packages (from cryptography>=2.5->azure-identity) (1.16.0)\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity) (2.8.0)\n",
      "Requirement already satisfied: portalocker<3,>=1.4 in /opt/anaconda3/lib/python3.12/site-packages (from msal-extensions>=1.2.0->azure-identity) (2.10.1)\n",
      "Requirement already satisfied: pycparser in /opt/anaconda3/lib/python3.12/site-packages (from cffi>=1.12->cryptography>=2.5->azure-identity) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.21.0->azure-core>=1.31.0->azure-identity) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.21.0->azure-core>=1.31.0->azure-identity) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.21.0->azure-core>=1.31.0->azure-identity) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.21.0->azure-core>=1.31.0->azure-identity) (2024.6.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: datasets==2.9.0 in /opt/anaconda3/lib/python3.12/site-packages (2.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.12/site-packages (from datasets==2.9.0) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from datasets==2.9.0) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.7 in /opt/anaconda3/lib/python3.12/site-packages (from datasets==2.9.0) (0.3.6)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (from datasets==2.9.0) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/anaconda3/lib/python3.12/site-packages (from datasets==2.9.0) (2.32.2)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/anaconda3/lib/python3.12/site-packages (from datasets==2.9.0) (4.66.4)\n",
      "Requirement already satisfied: xxhash in /opt/anaconda3/lib/python3.12/site-packages (from datasets==2.9.0) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /opt/anaconda3/lib/python3.12/site-packages (from datasets==2.9.0) (0.70.14)\n",
      "Requirement already satisfied: fsspec>=2021.11.1 in /opt/anaconda3/lib/python3.12/site-packages (from fsspec[http]>=2021.11.1->datasets==2.9.0) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in /opt/anaconda3/lib/python3.12/site-packages (from datasets==2.9.0) (3.9.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from datasets==2.9.0) (0.26.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from datasets==2.9.0) (23.2)\n",
      "Requirement already satisfied: responses<0.19 in /opt/anaconda3/lib/python3.12/site-packages (from datasets==2.9.0) (0.18.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from datasets==2.9.0) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets==2.9.0) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets==2.9.0) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets==2.9.0) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets==2.9.0) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets==2.9.0) (1.9.3)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets==2.9.0) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets==2.9.0) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.19.0->datasets==2.9.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.19.0->datasets==2.9.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.19.0->datasets==2.9.0) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.19.0->datasets==2.9.0) (2024.6.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->datasets==2.9.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->datasets==2.9.0) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->datasets==2.9.0) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.9.0) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: mlflow in /opt/anaconda3/lib/python3.12/site-packages (2.17.0)\n",
      "Requirement already satisfied: mlflow-skinny==2.17.0 in /opt/anaconda3/lib/python3.12/site-packages (from mlflow) (2.17.0)\n",
      "Requirement already satisfied: Flask<4 in /opt/anaconda3/lib/python3.12/site-packages (from mlflow) (3.0.3)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in /opt/anaconda3/lib/python3.12/site-packages (from mlflow) (1.13.3)\n",
      "Requirement already satisfied: docker<8,>=4.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from mlflow) (7.1.0)\n",
      "Requirement already satisfied: graphene<4 in /opt/anaconda3/lib/python3.12/site-packages (from mlflow) (3.4)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in /opt/anaconda3/lib/python3.12/site-packages (from mlflow) (3.4.1)\n",
      "Requirement already satisfied: matplotlib<4 in /opt/anaconda3/lib/python3.12/site-packages (from mlflow) (3.8.4)\n",
      "Requirement already satisfied: numpy<3 in /opt/anaconda3/lib/python3.12/site-packages (from mlflow) (1.26.4)\n",
      "Requirement already satisfied: pandas<3 in /opt/anaconda3/lib/python3.12/site-packages (from mlflow) (2.2.2)\n",
      "Requirement already satisfied: pyarrow<18,>=4.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from mlflow) (17.0.0)\n",
      "Requirement already satisfied: scikit-learn<2 in /opt/anaconda3/lib/python3.12/site-packages (from mlflow) (1.4.2)\n",
      "Requirement already satisfied: scipy<2 in /opt/anaconda3/lib/python3.12/site-packages (from mlflow) (1.13.1)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from mlflow) (2.0.30)\n",
      "Requirement already satisfied: Jinja2<4,>=2.11 in /opt/anaconda3/lib/python3.12/site-packages (from mlflow) (3.1.4)\n",
      "Requirement already satisfied: gunicorn<24 in /opt/anaconda3/lib/python3.12/site-packages (from mlflow) (23.0.0)\n",
      "Requirement already satisfied: cachetools<6,>=5.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from mlflow-skinny==2.17.0->mlflow) (5.3.3)\n",
      "Requirement already satisfied: click<9,>=7.0 in /opt/anaconda3/lib/python3.12/site-packages (from mlflow-skinny==2.17.0->mlflow) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle<4 in /opt/anaconda3/lib/python3.12/site-packages (from mlflow-skinny==2.17.0->mlflow) (2.2.1)\n",
      "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /opt/anaconda3/lib/python3.12/site-packages (from mlflow-skinny==2.17.0->mlflow) (0.36.0)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in /opt/anaconda3/lib/python3.12/site-packages (from mlflow-skinny==2.17.0->mlflow) (3.1.37)\n",
      "Requirement already satisfied: importlib-metadata!=4.7.0,<9,>=3.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from mlflow-skinny==2.17.0->mlflow) (7.0.1)\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /opt/anaconda3/lib/python3.12/site-packages (from mlflow-skinny==2.17.0->mlflow) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /opt/anaconda3/lib/python3.12/site-packages (from mlflow-skinny==2.17.0->mlflow) (1.27.0)\n",
      "Requirement already satisfied: packaging<25 in /opt/anaconda3/lib/python3.12/site-packages (from mlflow-skinny==2.17.0->mlflow) (23.2)\n",
      "Requirement already satisfied: protobuf<6,>=3.12.0 in /opt/anaconda3/lib/python3.12/site-packages (from mlflow-skinny==2.17.0->mlflow) (3.20.3)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from mlflow-skinny==2.17.0->mlflow) (6.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in /opt/anaconda3/lib/python3.12/site-packages (from mlflow-skinny==2.17.0->mlflow) (2.32.2)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from mlflow-skinny==2.17.0->mlflow) (0.5.1)\n",
      "Requirement already satisfied: Mako in /opt/anaconda3/lib/python3.12/site-packages (from alembic!=1.10.0,<2->mlflow) (1.3.6)\n",
      "Requirement already satisfied: typing-extensions>=4 in /opt/anaconda3/lib/python3.12/site-packages (from alembic!=1.10.0,<2->mlflow) (4.11.0)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /opt/anaconda3/lib/python3.12/site-packages (from docker<8,>=4.0.0->mlflow) (2.2.2)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from Flask<4->mlflow) (3.0.3)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from Flask<4->mlflow) (2.2.0)\n",
      "Requirement already satisfied: blinker>=1.6.2 in /opt/anaconda3/lib/python3.12/site-packages (from Flask<4->mlflow) (1.6.2)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in /opt/anaconda3/lib/python3.12/site-packages (from graphene<4->mlflow) (3.2.5)\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /opt/anaconda3/lib/python3.12/site-packages (from graphene<4->mlflow) (3.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from Jinja2<4,>=2.11->mlflow) (2.1.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib<4->mlflow) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib<4->mlflow) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib<4->mlflow) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib<4->mlflow) (1.4.4)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib<4->mlflow) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib<4->mlflow) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib<4->mlflow) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas<3->mlflow) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas<3->mlflow) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn<2->mlflow) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn<2->mlflow) (2.2.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.0.1)\n",
      "Requirement already satisfied: google-auth~=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.0->mlflow) (2.35.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.17.0->mlflow) (4.0.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/anaconda3/lib/python3.12/site-packages (from importlib-metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.17.0->mlflow) (3.17.0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /opt/anaconda3/lib/python3.12/site-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.17.0->mlflow) (1.2.14)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.48b0 in /opt/anaconda3/lib/python3.12/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.17.0->mlflow) (0.48b0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib<4->mlflow) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.17.0->mlflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.17.0->mlflow) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.17.0->mlflow) (2024.6.2)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/anaconda3/lib/python3.12/site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.17.0->mlflow) (1.14.1)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.17.0->mlflow) (4.0.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/anaconda3/lib/python3.12/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.0->mlflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/anaconda3/lib/python3.12/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.0->mlflow) (4.9)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/anaconda3/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.0->mlflow) (0.4.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: azureml-mlflow in /opt/anaconda3/lib/python3.12/site-packages (1.58.0)\n",
      "Requirement already satisfied: jsonpickle in /opt/anaconda3/lib/python3.12/site-packages (from azureml-mlflow) (3.3.0)\n",
      "Requirement already satisfied: mlflow-skinny in /opt/anaconda3/lib/python3.12/site-packages (from azureml-mlflow) (2.17.0)\n",
      "Requirement already satisfied: azure-identity in /opt/anaconda3/lib/python3.12/site-packages (from azureml-mlflow) (1.19.0)\n",
      "Requirement already satisfied: msrest>=0.6.18 in /opt/anaconda3/lib/python3.12/site-packages (from azureml-mlflow) (0.7.1)\n",
      "Requirement already satisfied: azure-core!=1.22.0,<2.0.0,>=1.8.0 in /opt/anaconda3/lib/python3.12/site-packages (from azureml-mlflow) (1.31.0)\n",
      "Requirement already satisfied: azure-mgmt-core<2.0.0,>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from azureml-mlflow) (1.4.0)\n",
      "Collecting azure-storage-blob<=12.19.0,>=12.5.0 (from azureml-mlflow)\n",
      "  Using cached azure_storage_blob-12.19.0-py3-none-any.whl.metadata (26 kB)\n",
      "Requirement already satisfied: azure-common<2.0.0,>=1.1 in /opt/anaconda3/lib/python3.12/site-packages (from azureml-mlflow) (1.1.28)\n",
      "Requirement already satisfied: cryptography in /opt/anaconda3/lib/python3.12/site-packages (from azureml-mlflow) (42.0.5)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.7.3 in /opt/anaconda3/lib/python3.12/site-packages (from azureml-mlflow) (2.9.0.post0)\n",
      "Requirement already satisfied: requests>=2.21.0 in /opt/anaconda3/lib/python3.12/site-packages (from azure-core!=1.22.0,<2.0.0,>=1.8.0->azureml-mlflow) (2.32.2)\n",
      "Requirement already satisfied: six>=1.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from azure-core!=1.22.0,<2.0.0,>=1.8.0->azureml-mlflow) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from azure-core!=1.22.0,<2.0.0,>=1.8.0->azureml-mlflow) (4.11.0)\n",
      "Requirement already satisfied: isodate>=0.6.1 in /opt/anaconda3/lib/python3.12/site-packages (from azure-storage-blob<=12.19.0,>=12.5.0->azureml-mlflow) (0.7.2)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/anaconda3/lib/python3.12/site-packages (from cryptography->azureml-mlflow) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from msrest>=0.6.18->azureml-mlflow) (2024.6.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from msrest>=0.6.18->azureml-mlflow) (2.0.0)\n",
      "Requirement already satisfied: msal>=1.30.0 in /opt/anaconda3/lib/python3.12/site-packages (from azure-identity->azureml-mlflow) (1.31.0)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from azure-identity->azureml-mlflow) (1.2.0)\n",
      "Requirement already satisfied: cachetools<6,>=5.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from mlflow-skinny->azureml-mlflow) (5.3.3)\n",
      "Requirement already satisfied: click<9,>=7.0 in /opt/anaconda3/lib/python3.12/site-packages (from mlflow-skinny->azureml-mlflow) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle<4 in /opt/anaconda3/lib/python3.12/site-packages (from mlflow-skinny->azureml-mlflow) (2.2.1)\n",
      "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /opt/anaconda3/lib/python3.12/site-packages (from mlflow-skinny->azureml-mlflow) (0.36.0)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in /opt/anaconda3/lib/python3.12/site-packages (from mlflow-skinny->azureml-mlflow) (3.1.37)\n",
      "Requirement already satisfied: importlib-metadata!=4.7.0,<9,>=3.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from mlflow-skinny->azureml-mlflow) (7.0.1)\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /opt/anaconda3/lib/python3.12/site-packages (from mlflow-skinny->azureml-mlflow) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /opt/anaconda3/lib/python3.12/site-packages (from mlflow-skinny->azureml-mlflow) (1.27.0)\n",
      "Requirement already satisfied: packaging<25 in /opt/anaconda3/lib/python3.12/site-packages (from mlflow-skinny->azureml-mlflow) (23.2)\n",
      "Requirement already satisfied: protobuf<6,>=3.12.0 in /opt/anaconda3/lib/python3.12/site-packages (from mlflow-skinny->azureml-mlflow) (3.20.3)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from mlflow-skinny->azureml-mlflow) (6.0.1)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from mlflow-skinny->azureml-mlflow) (0.5.1)\n",
      "Requirement already satisfied: pycparser in /opt/anaconda3/lib/python3.12/site-packages (from cffi>=1.12->cryptography->azureml-mlflow) (2.21)\n",
      "Requirement already satisfied: google-auth~=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny->azureml-mlflow) (2.35.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny->azureml-mlflow) (4.0.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/anaconda3/lib/python3.12/site-packages (from importlib-metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny->azureml-mlflow) (3.17.0)\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity->azureml-mlflow) (2.8.0)\n",
      "Requirement already satisfied: portalocker<3,>=1.4 in /opt/anaconda3/lib/python3.12/site-packages (from msal-extensions>=1.2.0->azure-identity->azureml-mlflow) (2.10.1)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /opt/anaconda3/lib/python3.12/site-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny->azureml-mlflow) (1.2.14)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.48b0 in /opt/anaconda3/lib/python3.12/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny->azureml-mlflow) (0.48b0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.21.0->azure-core!=1.22.0,<2.0.0,>=1.8.0->azureml-mlflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.21.0->azure-core!=1.22.0,<2.0.0,>=1.8.0->azureml-mlflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.21.0->azure-core!=1.22.0,<2.0.0,>=1.8.0->azureml-mlflow) (2.2.2)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.18->azureml-mlflow) (3.2.2)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/anaconda3/lib/python3.12/site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny->azureml-mlflow) (1.14.1)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny->azureml-mlflow) (4.0.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/anaconda3/lib/python3.12/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny->azureml-mlflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/anaconda3/lib/python3.12/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny->azureml-mlflow) (4.9)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/anaconda3/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny->azureml-mlflow) (0.4.8)\n",
      "Using cached azure_storage_blob-12.19.0-py3-none-any.whl (394 kB)\n",
      "Installing collected packages: azure-storage-blob\n",
      "  Attempting uninstall: azure-storage-blob\n",
      "    Found existing installation: azure-storage-blob 12.23.1\n",
      "    Uninstalling azure-storage-blob-12.23.1:\n",
      "      Successfully uninstalled azure-storage-blob-12.23.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "azure-storage-file-datalake 12.17.0 requires azure-storage-blob>=12.23.0, but you have azure-storage-blob 12.19.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed azure-storage-blob-12.19.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install azure-ai-ml\n",
    "%pip install azure-identity\n",
    "%pip install datasets==2.9.0\n",
    "%pip install mlflow\n",
    "%pip install azureml-mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import (\n",
    "    DefaultAzureCredential,\n",
    "    InteractiveBrowserCredential,\n",
    ")\n",
    "from azure.ai.ml.entities import AmlCompute\n",
    "import time\n",
    "\n",
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    credential = InteractiveBrowserCredential()\n",
    "\n",
    "try:\n",
    "    workspace_ml_client = MLClient.from_config(credential=credential)\n",
    "except:\n",
    "    workspace_ml_client = MLClient(\n",
    "        credential,\n",
    "        subscription_id=\"AddyoursubscriptionGUID\",\n",
    "        resource_group_name=\"Addyourresorcesgroupname\",\n",
    "        workspace_name=\"Addyourworkspacename\",\n",
    "    )\n",
    "\n",
    "# the models, fine tuning pipelines and environments are available in the AzureML registry, \"azureml\"\n",
    "registry_ml_client = MLClient(credential, registry_name=\"azureml\")\n",
    "experiment_name = \"phi35-mini-ft-sentiment\"\n",
    "\n",
    "# generating a unique timestamp that can be used for names and versions that need to be unique\n",
    "timestamp = str(int(time.time()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Pick a foundation model to fine tune\n",
    "\n",
    "`Phi-3.5-mini-instruct` is a lightweight, state-of-the-art open model built upon datasets used for `Phi-3` models, with a focus on very high-quality, reasoning dense data. The model belongs to the `Phi-3` model family and supports `128k` token context length. The model underwent a rigorous enhancement process, incorporating both supervised fine-tuning, proximal policy optimization, and direct preference optimization to ensure precise instruction adherence and robust safety measures.\n",
    "\n",
    "You can browse these models in the Model Catalog in the AzureML Studio, filtering by the `chat-completion` task. In this example, we use the `Phi-3.5-mini-instruct` model. If you have opened this notebook for a different model, replace the model name and version accordingly. \n",
    "\n",
    "Note the model id property of the model. This will be passed as input to the fine tuning job. This is also available as the `Asset ID` field in model details page in AzureML Studio Model Catalog. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Using model name: Phi-3.5-mini-instruct, version: 4, id: azureml://registries/azureml/models/Phi-3.5-mini-instruct/versions/4 for fine tuning\n"
     ]
    }
   ],
   "source": [
    "model_name = \"Phi-3.5-mini-instruct\"\n",
    "foundation_model = registry_ml_client.models.get(model_name, label=\"latest\")\n",
    "print(\n",
    "    \"\\n\\nUsing model name: {0}, version: {1}, id: {2} for fine tuning\".format(\n",
    "        foundation_model.name, foundation_model.version, foundation_model.id\n",
    "    )\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create a compute to be used with the job\n",
    "\n",
    "The finetune job works `ONLY` with `GPU` compute. The size of the compute depends on how big the model is and in most cases it becomes tricky to identify the right compute for the job. In this cell, we guide the user to select the right compute for the job.\n",
    "* The computes listed below work with the most optimized configuration. Any changes to the configuration might lead to `Cuda Out Of Memory` error. In such cases, try to upgrade the compute to a bigger compute size.\n",
    "* While selecting the compute_cluster_size below, make sure the compute is available in your resource group. If a particular compute is not available you can make a request to get access to the compute resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please create a compute from the above list - ['Standard_NC24ads_A100_v4', 'Standard_NC48ads_A100_v4', 'Standard_NC96ads_A100_v4', 'Standard_ND96amsr_A100_v4']\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "if \"finetune_compute_allow_list\" in foundation_model.tags:\n",
    "    computes_allow_list = ast.literal_eval(\n",
    "        foundation_model.tags[\"finetune_compute_allow_list\"]\n",
    "    )  # convert string to python list\n",
    "    print(f\"Please create a compute from the above list - {computes_allow_list}\")\n",
    "else:\n",
    "    computes_allow_list = None\n",
    "    print(\"`finetune_compute_allow_list` is not part of model tags\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The compute cluster already exists! Reusing it for the current run\n",
      "Number of GPU's in compute Standard_NC96ads_A100_v4: 4\n"
     ]
    }
   ],
   "source": [
    "# If you have a specific compute size to work with change it here. By default we use the 8 x V100 compute from the above list\n",
    "compute_cluster_size = \"Standard_NC96ads_A100_v4\"\n",
    "\n",
    "# If you already have a gpu cluster, mention it here. Else will create a new one with the name 'gpu-cluster-big'\n",
    "compute_cluster = \"ignite2024demo\"\n",
    "\n",
    "try:\n",
    "    compute = workspace_ml_client.compute.get(compute_cluster)\n",
    "    print(\"The compute cluster already exists! Reusing it for the current run\")\n",
    "except Exception as ex:\n",
    "    print(\n",
    "        f\"Looks like the compute cluster doesn't exist. Creating a new one with compute size {compute_cluster_size}!\"\n",
    "    )\n",
    "    try:\n",
    "        print(\"Attempt #1 - Trying to create a dedicated compute\")\n",
    "        compute = AmlCompute(\n",
    "            name=compute_cluster,\n",
    "            size=compute_cluster_size,\n",
    "            tier=\"Dedicated\",\n",
    "            max_instances=2,  # For multi node training set this to an integer value more than 1\n",
    "        )\n",
    "        workspace_ml_client.compute.begin_create_or_update(compute).wait()\n",
    "    except Exception as e:\n",
    "        try:\n",
    "            print(\n",
    "                \"Attempt #2 - Trying to create a low priority compute. Since this is a low priority compute, the job could get pre-empted before completion.\"\n",
    "            )\n",
    "            compute = AmlCompute(\n",
    "                name=compute_cluster,\n",
    "                size=compute_cluster_size,\n",
    "                tier=\"LowPriority\",\n",
    "                max_instances=2,  # For multi node training set this to an integer value more than 1\n",
    "            )\n",
    "            workspace_ml_client.compute.begin_create_or_update(compute).wait()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            raise ValueError(\n",
    "                f\"WARNING! Compute size {compute_cluster_size} not available in workspace\"\n",
    "            )\n",
    "\n",
    "\n",
    "# Sanity check on the created compute\n",
    "compute = workspace_ml_client.compute.get(compute_cluster)\n",
    "if compute.provisioning_state.lower() == \"failed\":\n",
    "    raise ValueError(\n",
    "        f\"Provisioning failed, Compute '{compute_cluster}' is in failed state. \"\n",
    "        f\"please try creating a different compute\"\n",
    "    )\n",
    "\n",
    "if computes_allow_list is not None:\n",
    "    computes_allow_list_lower_case = [x.lower() for x in computes_allow_list]\n",
    "    if compute.size.lower() not in computes_allow_list_lower_case:\n",
    "        raise ValueError(\n",
    "            f\"VM size {compute.size} is not in the allow-listed computes for finetuning\"\n",
    "        )\n",
    "else:\n",
    "    # Computes with K80 GPUs are not supported\n",
    "    unsupported_gpu_vm_list = [\n",
    "        \"standard_nc6\",\n",
    "        \"standard_nc12\",\n",
    "        \"standard_nc24\",\n",
    "        \"standard_nc24r\",\n",
    "    ]\n",
    "    if compute.size.lower() in unsupported_gpu_vm_list:\n",
    "        raise ValueError(\n",
    "            f\"VM size {compute.size} is currently not supported for finetuning\"\n",
    "        )\n",
    "\n",
    "\n",
    "# This is the number of GPUs in a single node of the selected 'vm_size' compute.\n",
    "# Setting this to less than the number of GPUs will result in underutilized GPUs, taking longer to train.\n",
    "# Setting this to more than the number of GPUs will result in an error.\n",
    "gpu_count_found = False\n",
    "workspace_compute_sku_list = workspace_ml_client.compute.list_sizes()\n",
    "available_sku_sizes = []\n",
    "for compute_sku in workspace_compute_sku_list:\n",
    "    available_sku_sizes.append(compute_sku.name)\n",
    "    if compute_sku.name.lower() == compute.size.lower():\n",
    "        gpus_per_node = compute_sku.gpus\n",
    "        gpu_count_found = True\n",
    "# if gpu_count_found not found, then print an error\n",
    "if gpu_count_found:\n",
    "    print(f\"Number of GPU's in compute {compute.size}: {gpus_per_node}\")\n",
    "else:\n",
    "    raise ValueError(\n",
    "        f\"Number of GPU's in compute {compute.size} not found. Available skus are: {available_sku_sizes}.\"\n",
    "        f\"This should not happen. Please check the selected compute cluster: {compute_cluster} and try again.\"\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Prepare the dataset for fine-tuning the model\n",
    "\n",
    "For this demo, we want to showcase finetuning `Phi-3.5-mini-instruct` model with sentiment classification data. Below is a snippet of our training data `train.jsonl` that we have prepared with 50k+ prompt-response sets that finetune the model to classify content sentiments in a particular way. \n",
    "\n",
    "\n",
    "``` json\n",
    "{\n",
    "    \"prompt_id\": 100,\n",
    "    \"prompt\": \"XXX Recovers XXX Website After Ransomware Attack.\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"content\": \"XXX Recovers XXX Website After Ransomware Attack. What is the sentiment of this news? Please choose an answer from {negative/neutral/positive}.\",\n",
    "            \"role\": \"user\"\n",
    "        },\n",
    "        {\n",
    "            \"content\": \"negative\",\"role\": \"assistant\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "In addition to the `training` dataset, we also specify a `validation` dataset, that is in the same form as the training dataset but with different values. Training datasets are used to fit machine learning models that 'teach' or 'train the model. In contrast, validation datasets contain different samples to *evaluate* the trained ML models by assessing the model performance and finetuning the parameters of the model. This becomes an iterative process of the model learning from the training data, and then gets validated on the validation set. A validation dataset tells us how well the model is learning and adapting, allowing for adjustments and optimizations to be made to the model's parameters or hyperparameters before it's finally put to the test."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Submit the fine tuning job using the the model and data as inputs\n",
    " \n",
    "Create the job that uses the `chat-completion` pipeline component. [Learn more](https://github.com/Azure/azureml-assets/blob/main/assets/training/finetune_acft_hf_nlp/components/pipeline_components/chat_completion/README.md) about all the parameters supported for fine tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training parameters define the training aspects. Below are few of the parameters that belong to this category.\n",
    "* learning rate\n",
    "* number of training steps\n",
    "* batch size\n",
    "\n",
    "Optimization parameters help in optimizing the GPU memory and effectively using the compute resources. Below are few of the parameters that belong to this category. _The optimization parameters differs for each model and are packaged with the model to handle these variations._\n",
    "* deepspeed and LoRA\n",
    "* mixed precision training\n",
    "* multi-node training \n",
    "\n",
    "Note: Supervised finetuning may result in loosing alignment or catastrophic forgetting. We recommend checking for this issue and running an alignment stage after you finetune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following finetune parameters are going to be set for the run: {'num_train_epochs': 5, 'per_device_train_batch_size': 1, 'per_device_eval_batch_size': 8, 'learning_rate': 5e-06, 'lr_scheduler_type': 'cosine', 'apply_lora': 'true', 'merge_lora_weights': 'true', 'lora_alpha': 32, 'lora_r': 8, 'lora_dropout': 0, 'apply_ort': 'false', 'apply_deepspeed': 'true', 'deepspeed_stage': 2, 'ignore_mismatched_sizes': 'false', 'precision': 16, 'evaluation_strategy': 'steps', 'eval_steps': 50, 'logging_strategy': 'steps', 'logging_steps': 10, 'save_total_limit': 1, 'apply_early_stopping': 'true', 'early_stopping_patience': 3, 'batch_size': 1, 'max_seq_length': 4096}\n"
     ]
    }
   ],
   "source": [
    "# Default training parameters\n",
    "training_parameters = dict(\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=8,\n",
    "    learning_rate=5e-6,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    ")\n",
    "# Default optimization parameters\n",
    "optimization_parameters = dict(\n",
    "    apply_lora=\"true\",\n",
    "    merge_lora_weights=\"true\",\n",
    "    lora_alpha=32,\n",
    "    lora_r=8,\n",
    "    lora_dropout=0,\n",
    "    apply_ort=\"false\",\n",
    "    apply_deepspeed=\"true\",\n",
    "    deepspeed_stage=2,\n",
    "    ignore_mismatched_sizes=\"false\",\n",
    "    precision=16,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50, # make this 5 for smaller dataset\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=10,\n",
    "    save_total_limit=1,\n",
    "    apply_early_stopping=\"true\",\n",
    "    early_stopping_patience=3,\n",
    "    batch_size=1,\n",
    "    max_seq_length=4096,\n",
    ")\n",
    "# Let's construct finetuning parameters using training and optimization paramters.\n",
    "finetune_parameters = {**training_parameters, **optimization_parameters}\n",
    "\n",
    "# Each model finetuning works best with certain finetuning parameters which are packed with model as `model_specific_defaults`.\n",
    "# Let's override the finetune_parameters in case the model has some custom defaults.\n",
    "# if \"model_specific_defaults\" in foundation_model.tags:\n",
    "#     print(\"Warning! Model specific defaults exist. The defaults could be overridden.\")\n",
    "#     finetune_parameters.update(\n",
    "#         ast.literal_eval(  # convert string to python dict\n",
    "#             foundation_model.tags[\"model_specific_defaults\"]\n",
    "#         )\n",
    "#     )\n",
    "print(\n",
    "    f\"The following finetune parameters are going to be set for the run: {finetune_parameters}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Display name used for the run: Phi-3.5-mini-instruct-phi35mini-sentiment-bs32-cosine-ds2-lora-save_limit1-seqlen4096\n"
     ]
    }
   ],
   "source": [
    "# Set the pipeline display name for distinguishing different runs from the name\n",
    "def get_pipeline_display_name():\n",
    "    batch_size = (\n",
    "        int(finetune_parameters.get(\"per_device_train_batch_size\", 1))\n",
    "        * int(finetune_parameters.get(\"gradient_accumulation_steps\", 8))\n",
    "        * int(gpus_per_node)\n",
    "        * int(finetune_parameters.get(\"num_nodes_finetune\", 1))\n",
    "    )\n",
    "    scheduler = finetune_parameters.get(\"lr_scheduler_type\", \"cosine\")\n",
    "    deepspeed = finetune_parameters.get(\"apply_deepspeed\", \"true\")\n",
    "    ds_stage = finetune_parameters.get(\"deepspeed_stage\", \"2\")\n",
    "    if deepspeed == \"true\":\n",
    "        ds_string = f\"ds{ds_stage}\"\n",
    "    else:\n",
    "        ds_string = \"nods\"\n",
    "    lora = finetune_parameters.get(\"apply_lora\", \"true\")\n",
    "    if lora == \"true\":\n",
    "        lora_string = \"lora\"\n",
    "    else:\n",
    "        lora_string = \"nolora\"\n",
    "    save_limit = finetune_parameters.get(\"save_total_limit\", -1)\n",
    "    seq_len = finetune_parameters.get(\"max_seq_length\", -1)\n",
    "    return (\n",
    "        model_name\n",
    "        + \"-\"\n",
    "        + \"phi35mini-sentiment\"\n",
    "        + \"-\"\n",
    "        + f\"bs{batch_size}\"\n",
    "        + \"-\"\n",
    "        + f\"{scheduler}\"\n",
    "        + \"-\"\n",
    "        + ds_string\n",
    "        + \"-\"\n",
    "        + lora_string\n",
    "        + f\"-save_limit{save_limit}\"\n",
    "        + f\"-seqlen{seq_len}\"\n",
    "    )\n",
    "\n",
    "\n",
    "pipeline_display_name = get_pipeline_display_name()\n",
    "print(f\"Display name used for the run: {pipeline_display_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.dsl import pipeline\n",
    "from azure.ai.ml import Input\n",
    "\n",
    "# fetch the pipeline component\n",
    "pipeline_component_func = registry_ml_client.components.get(\n",
    "    name=\"chat_completion_pipeline\", label=\"latest\"\n",
    ")\n",
    "\n",
    "\n",
    "# define the pipeline job\n",
    "@pipeline(name=pipeline_display_name)\n",
    "def create_pipeline():\n",
    "    chat_completion_pipeline = pipeline_component_func(\n",
    "        mlflow_model_path=foundation_model.id,\n",
    "        compute_model_import=compute_cluster,\n",
    "        compute_preprocess=compute_cluster,\n",
    "        compute_finetune=compute_cluster,\n",
    "        compute_model_evaluation=compute_cluster,\n",
    "        # map the dataset splits to parameters\n",
    "        train_file_path=Input(\n",
    "            type=\"uri_file\", path=\"./finance_data/fingpt-sentiment-train/train.jsonl\"\n",
    "        ),\n",
    "        test_file_path=Input(\n",
    "            type=\"uri_file\", path=\"./finance_benchmarks/fiqa_sa/fiqa_sa.jsonl\"\n",
    "        ),\n",
    "        # Training settings\n",
    "        number_of_gpu_to_use_finetuning=gpus_per_node,  # set to the number of GPUs available in the compute\n",
    "        **finetune_parameters\n",
    "    )\n",
    "    return {\n",
    "        # map the output of the fine tuning job to the output of pipeline job so that we can easily register the fine tuned model\n",
    "        # registering the model is required to deploy the model to an online or batch endpoint\n",
    "        \"trained_model\": chat_completion_pipeline.outputs.mlflow_model_folder\n",
    "    }\n",
    "\n",
    "\n",
    "pipeline_object = create_pipeline()\n",
    "\n",
    "# don't use cached results from previous jobs\n",
    "pipeline_object.settings.force_rerun = True\n",
    "\n",
    "# set continue on step failure to False\n",
    "pipeline_object.settings.continue_on_step_failure = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "\u001b[32mUploading train.jsonl\u001b[32m (< 1 MB): 100%|█████████| 350k/350k [00:01<00:00, 226kB/s]\u001b[0m\n",
      "\u001b[39m\n",
      "\n",
      "\u001b[32mUploading fiqa_sa.jsonl\u001b[32m (< 1 MB): 100%|██████| 530k/530k [00:00<00:00, 1.07MB/s]\u001b[0m\n",
      "\u001b[39m\n",
      "\n",
      "pathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.MLFlowModelJobOutput'> and will be ignored\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: red_shark_xwwvvcl0z3\n",
      "Web View: https://ml.azure.com/runs/red_shark_xwwvvcl0z3?wsid=/subscriptions/d676d072-7cbf-4197-b2d6-17ecf38370d0/resourcegroups/Ignite2024-Demo/workspaces/Ignite2024-Demo\n",
      "\n",
      "Streaming logs/azureml/executionlogs.txt\n",
      "========================================\n",
      "\n",
      "[2024-11-11 22:28:37Z] Submitting 1 runs, first five are: 6ce7a840:0b0ed5e9-8199-4885-85aa-b7e1dc29a017\n",
      "[2024-11-11 22:59:59Z] Completing processing run id 0b0ed5e9-8199-4885-85aa-b7e1dc29a017.\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: red_shark_xwwvvcl0z3\n",
      "Web View: https://ml.azure.com/runs/red_shark_xwwvvcl0z3?wsid=/subscriptions/d676d072-7cbf-4197-b2d6-17ecf38370d0/resourcegroups/Ignite2024-Demo/workspaces/Ignite2024-Demo\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# submit the pipeline job\n",
    "pipeline_job = workspace_ml_client.jobs.create_or_update(\n",
    "    pipeline_object, experiment_name=experiment_name\n",
    ")\n",
    "# wait for the pipeline job to complete\n",
    "workspace_ml_client.jobs.stream(pipeline_job.name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Register the fine tuned model with the workspace\n",
    "\n",
    "We will register the model from the output of the fine tuning job. This will track lineage between the fine tuned model and the fine tuning job. The fine tuning job, further, tracks lineage to the foundation model, data and training code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline job outputs:  {'trained_model': <azure.ai.ml.entities._job.pipeline._io.base.PipelineOutput object at 0x114771eb0>}\n",
      "phi35mini-finetuned-sentiment\n",
      "path to register model:  azureml://jobs/red_shark_xwwvvcl0z3/outputs/trained_model\n",
      "prepare to register model: \n",
      " description: phi35mini-finetuned-sentiment\n",
      "name: phi35mini-finetuned-sentiment\n",
      "path: azureml://jobs/red_shark_xwwvvcl0z3/outputs/trained_model\n",
      "properties: {}\n",
      "tags: {}\n",
      "type: mlflow_model\n",
      "version: '1731362985'\n",
      "\n",
      "registered model: \n",
      " creation_context:\n",
      "  created_at: '2024-11-11T23:19:16.504930+00:00'\n",
      "  created_by: Gina Lee\n",
      "  created_by_type: User\n",
      "  last_modified_at: '2024-11-11T23:19:16.504930+00:00'\n",
      "  last_modified_by: Gina Lee\n",
      "  last_modified_by_type: User\n",
      "description: phi35mini-finetuned-sentiment\n",
      "flavors:\n",
      "  hftransformersv2:\n",
      "    code: code\n",
      "    hf_config_class: AutoConfig\n",
      "    hf_pretrained_class: AutoModelForCausalLM\n",
      "    hf_tokenizer_class: AutoTokenizer\n",
      "    model_data: data\n",
      "    pytorch_version: 2.2.2\n",
      "    task_type: chat-completion\n",
      "    tokenizer_config: \"{\\n  \\\"max_length\\\": \\\"4096\\\"\\n}\"\n",
      "    tokenizer_hf_load_kwargs: \"{\\n  \\\"clean_up_tokenization_spaces\\\": \\\"true\\\",\\n\\\n",
      "      \\  \\\"padding\\\": \\\"false\\\",\\n  \\\"padding_side\\\": \\\"left\\\",\\n  \\\"truncation\\\"\\\n",
      "      : \\\"true\\\"\\n}\"\n",
      "    train_label_list: ''\n",
      "    transformers_version: 4.44.0\n",
      "  python_function:\n",
      "    code: code\n",
      "    data: data\n",
      "    env: conda.yaml\n",
      "    loader_module: azureml.evaluate.mlflow.hftransformers\n",
      "    python_version: 3.10.15\n",
      "id: azureml:/subscriptions/d676d072-7cbf-4197-b2d6-17ecf38370d0/resourceGroups/Ignite2024-Demo/providers/Microsoft.MachineLearningServices/workspaces/Ignite2024-Demo/models/phi35mini-finetuned-sentiment/versions/1731362985\n",
      "job_name: red_shark_xwwvvcl0z3\n",
      "name: phi35mini-finetuned-sentiment\n",
      "path: azureml://subscriptions/d676d072-7cbf-4197-b2d6-17ecf38370d0/resourceGroups/Ignite2024-Demo/workspaces/Ignite2024-Demo/datastores/workspaceblobstore/paths/azureml/82626eda-117a-49c2-98a4-ce1a5ec92dea/mlflow_model_folder/\n",
      "properties: {}\n",
      "stage: Development\n",
      "tags: {}\n",
      "type: mlflow_model\n",
      "version: '1731362985'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import Model\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "# check if the `trained_model` output is available\n",
    "print(\"pipeline job outputs: \", workspace_ml_client.jobs.get(pipeline_job.name).outputs)\n",
    "\n",
    "# fetch the model from pipeline job output - not working, hence fetching from fine tune child job\n",
    "model_path_from_job = \"azureml://jobs/{0}/outputs/{1}\".format(\n",
    "    pipeline_job.name, \"trained_model\"\n",
    ")\n",
    "\n",
    "finetuned_model_name = \"phi35mini-finetuned-sentiment\"\n",
    "print (finetuned_model_name)\n",
    "print(\"path to register model: \", model_path_from_job)\n",
    "prepare_to_register_model = Model(\n",
    "    path=model_path_from_job,\n",
    "    type=AssetTypes.MLFLOW_MODEL,\n",
    "    name=finetuned_model_name,\n",
    "    version=timestamp,  # use timestamp as version to avoid version conflict\n",
    "    description=\"phi35mini-finetuned-sentiment\",\n",
    ")\n",
    "print(\"prepare to register model: \\n\", prepare_to_register_model)\n",
    "# register the model from pipeline job output\n",
    "registered_model = workspace_ml_client.models.create_or_update(\n",
    "    prepare_to_register_model\n",
    ")\n",
    "print(\"registered model: \\n\", registered_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Deploy the fine tuned model to an online endpoint\n",
    "Online endpoints give a durable REST API that can be used to integrate with applications that need to use the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import (\n",
    "    ManagedOnlineEndpoint,\n",
    "    ManagedOnlineDeployment,\n",
    "    ProbeSettings,\n",
    "    OnlineRequestSettings,\n",
    ")\n",
    "\n",
    "# Create online endpoint - endpoint names need to be unique in a region, hence using timestamp to create unique endpoint name\n",
    "\n",
    "online_endpoint_name = \"phi35miniftignite2024-\" + timestamp\n",
    "# create an online endpoint\n",
    "endpoint = ManagedOnlineEndpoint(\n",
    "    name=online_endpoint_name,\n",
    "    description=\"Online endpoint for \"\n",
    "    + registered_model.name\n",
    "    + \", phi35mini sentimentdata\",\n",
    "    auth_mode=\"key\",\n",
    ")\n",
    "workspace_ml_client.begin_create_or_update(endpoint).wait()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find here the list of SKU's supported for deployment - [Managed online endpoints SKU list](https://learn.microsoft.com/en-us/azure/machine-learning/reference-managed-online-endpoints-vm-sku-list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "instance_type = \"Standard_NC24ads_A100_v4\"\n",
    "\n",
    "# Inference compute allow list that supports deployment\n",
    "if \"inference_compute_allow_list\" in foundation_model.tags:\n",
    "    inference_computes_allow_list = ast.literal_eval(\n",
    "        foundation_model.tags[\"inference_compute_allow_list\"]\n",
    "    )  # convert string to python list\n",
    "    print(f\"Please create a compute from the above list - {computes_allow_list}\")\n",
    "else:\n",
    "    inference_computes_allow_list = None\n",
    "    print(\"`inference_compute_allow_list` is not part of model tags\")\n",
    "\n",
    "# Check if the compute is in the allow listed computes\n",
    "if (\n",
    "    inference_computes_allow_list is not None\n",
    "    and instance_type not in inference_computes_allow_list\n",
    "):\n",
    "    print(\n",
    "        f\"`instance_type` is not in the allow listed compute. Please select a value from {inference_computes_allow_list}\"\n",
    "    )\n",
    "\n",
    "\n",
    "# create a deployment\n",
    "demo_deployment = ManagedOnlineDeployment(\n",
    "    name=\"phi35miniftignite24\",\n",
    "    endpoint_name=online_endpoint_name,\n",
    "    model=registered_model.id,\n",
    "    instance_type=instance_type,\n",
    "    instance_count=1,\n",
    "    liveness_probe=ProbeSettings(initial_delay=600),\n",
    "    request_settings=OnlineRequestSettings(request_timeout_ms=90000),\n",
    ")\n",
    "workspace_ml_client.online_deployments.begin_create_or_update(demo_deployment).wait()\n",
    "endpoint.traffic = {\"demo\": 100}\n",
    "workspace_ml_client.begin_create_or_update(endpoint).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Test the endpoint with sample data\n",
    "\n",
    "We will use some sample prompts from the test dataset and submit to online endpoint for inference to test the finetuned model.\n",
    "Below is a simple Python script to test the finetuned model in a terminal. After putting in your API Key and API endpoint, you can simply run this Python script to test different prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install azure-ai-inference\n",
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from colorama import init, Fore, Style\n",
    "\n",
    "# Initialize colorama\n",
    "init()\n",
    "\n",
    "\n",
    "api_key = '<YOUR API KEY>'\n",
    "if not api_key:\n",
    "  raise Exception(\"A key should be provided to invoke the endpoint\")\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint='<YOUR API ENDPOINT>',\n",
    "    credential=AzureKeyCredential(api_key)\n",
    ")\n",
    "\n",
    "model_info = client.get_model_info()\n",
    "print(\"Model name:\", model_info.model_name)\n",
    "print(\"Model type:\", model_info.model_type)\n",
    "print(\"Model provider name:\", model_info.model_provider_name)\n",
    "\n",
    "user_message = input(\"\\nUser: \")\n",
    "\n",
    "payload = {\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": user_message\n",
    "    }\n",
    "  ],\n",
    "  \"max_tokens\": 2048,\n",
    "  \"temperature\": 0.8,\n",
    "  \"top_p\": 0.1,\n",
    "  \"presence_penalty\": 0,\n",
    "  \"frequency_penalty\": 0\n",
    "}\n",
    "response = client.complete(payload)\n",
    "\n",
    "print(\"\\nResponse:\")\n",
    "print(Fore.YELLOW + response.choices[0].message.content + Style.RESET_ALL)\n",
    "#print(\"\\nModel:\", response.model)\n",
    "print(\"\\nUsage:\")\n",
    "print(\"\tPrompt tokens:\", response.usage.prompt_tokens)\n",
    "print(\"\tTotal tokens:\", response.usage.total_tokens)\n",
    "print(\"\tCompletion tokens:\", response.usage.completion_tokens)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. (Optional) Download the finetuned model\n",
    "\n",
    "If you would like to download a local copy of the finetuned model's tensors, you can go to Azure Machine Learning Studio, go to `Models`, select your finetuned model instance, and click on `Artifacts` tab to download individual files."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
